<img alt="Vincent Vallet" src="https://miro.medium.com/fit/c/96/96/1*vFTVh_mYyf0p6m7f77A3vw.jpeg" width="48" height="48"/><h1>Why CPU monitoring is important?</h1><p>I work at <a href="http://voodoo.io/" rel="noopener nofollow">Voodoo</a>, a French company that creates mobile video games. We have a lot of challenges with performance, availability, and scalability because of the insane amount of traffic our infrastructure supports (billions of events/requests per day …… no joke!). In this setting, every metric is important and gives us a lot of information about the state of our system.</p><p>When working with Node.js one of the most critical resources to monitor is the CPU. Most of the time, when working on a low traffic API or project we don’t realize how many simple lines of code can have a huge impact on CPU. On the other hand, when traffic increases, a simple mistake can cost dearly.</p><h1>Resources</h1><p>What kind of resources does your application need? In most cases, we focus on memory and CPU. Good monitoring of these two elements is mandatory for an application running on production.</p><p>For memory, constant monitoring is the best practice to track the worst developer nightmare a.k.a memory leak.</p><figure><img src="https://miro.medium.com/max/3788/1*5o3M5niyi911waUrKWVZ0Q.png" width="1894" height="970"/><figcaption>Memory leak in action</figcaption></figure><p>A good way to debug memory leak is a memory dump and/or memory sampling but this is not the subject.</p><p>(for more details about V8 and its garbage collector you can read my previous article <a rel="noopener" href="/voodoo-engineering/nodejs-internals-v8-garbage-collector-a6eca82540ec">here</a>)</p><blockquote><p>Stay focused on the CPU!</p></blockquote><p>Most of the time we monitor this resource with a simple solution allowing us to get a graph representing CPU consumption over time. If we want to be reactive we add an alarm, based on a threshold, to warn us when CPU usage is too high.</p><figure><img src="https://miro.medium.com/max/1994/1*8uOdeOfnUzTaFIY1r7oAMg.png" width="997" height="230"/><figcaption>Basic CPU monitoring</figcaption></figure><p>And what next? We don’t have data about the state of the instance when the CPU usage has increased. So we can’t determine why we had this peak, at least not without an important time of debugging, comparing log, etc. This is exactly why you need to use CPU profiling.</p><h1>CPU profiling: what’s the difference with CPU monitoring?</h1><blockquote><p>“Most commonly, profiling information serves to aid program optimization. Profiling is achieved by instrumenting either the program source code or its binary executable form using a tool called a profiler”</p></blockquote><p>Basically, for Node.js, CPU profiling is nothing more than collecting data about functions which are CPU consuming. And ideally, get a graphic representation of the collected data a.k.a “flame graph” or “flame chart”.</p><p>It will help you to track the exact file, line, and function which takes the most time to execute.</p><h1>What about existing solutions?</h1><h2>Add arguments to Node.js</h2><p>Node.js provides a way to collect data about CPU with two command lines.</p><p>The first command just executes your application, the argument just tells to V8 engine to collect data. When you stop your script all information is stored in a file.</p><pre><span>node --prof app.js</span></pre><figure><img src="https://miro.medium.com/max/1698/1*e7gjTlzi55udTXbbPeEs2A.png" width="849" height="534"/><figcaption>Output of — prof</figcaption></figure><p>It is not very clear, is it?</p><p>That’s why you just need to run this second command to transform your raw file into a more human-readable output.</p><pre><span>node --prof-process isolate-0xnnnnn-v8.log &gt; processed.txt</span></pre><figure><img src="https://miro.medium.com/max/1508/1*JJkRh7JihTUo2apW_9ZXAQ.png" width="754" height="306"/><figcaption>The output of — prof-process</figcaption></figure><p>It seems better, here you can determine which function consumes the most of CPU (percentage of the time).</p><h2>ClinicJs</h2><p>ClinicJs is a set of tools that allow you to collect data and display performance charts. With “clinic flame” you can generate a flame graph based on CPU consumption.</p><figure><img src="https://miro.medium.com/max/5760/1*6wi5BlNNnykjZs0PufrvLQ.png" width="2880" height="1534"/><figcaption>Flame chart</figcaption></figure><p>But once again, you have to stop your app, launch the tool, then terminate the script in order to display the graph (files are generated on the disk).</p><p>For more details, you can see the <a href="https://clinicjs.org/" rel="noopener nofollow">project</a>.</p><p><strong>To sum up</strong>, here is the list of drawbacks of the two previous solutions.</p><ul><li>Downtime (you should kill your application to collect the data)</li><li>Performance overhead</li><li>Data collected locally</li><li>Need external tools (ClinicJs)</li></ul><h1>And now, CPU profiling on-demand!</h1><p>We have an API that we want to test with autocannon tool. At this step, our project is able to serve around 200 requests in 20 seconds. There is probably a mistake somewhere in the code which slows down our application.</p><figure><img src="https://miro.medium.com/max/1694/1*cS9IXYGfMmgxaAUlC7oqOQ.png" width="847" height="362"/><figcaption>&lt;img class=&#34;s t u hy ai&#34; src=&#34;https://miro.medium.com/max/1694/1*cS9IXYGfMmgxaAUlC7oqOQ.png&#34; width=&#34;847&#34; height=&#34;362&#34; role=&#34;presentation&#34;/&gt;</figcaption></figure><p>But now, what if we want to trigger a CPU profiling remotely (without ssh connection to the server)? It’s possible using Websocket, SSE or any other technology to send a message to your instance.</p><p>Here is a simple example of a server using the “ws” module to send a message to a unique instance.</p><p><strong>What does it mean?</strong></p><p>The larger is a box (a function call) the more it consumed CPU. So a good CPU profiling should look like a “flame” graph where each stack is the finest possible.</p><p>In our example, every request try to generate a token. For this purpose, it calls the function pbkdf2 which is CPU consuming. Our CPU profile looks like a sequence of big blocks of time, like if the last function in the call stack takes 99% of the total time.</p><p>The CPU profiling after optimizations, with the same time range.</p><figure><img src="https://miro.medium.com/max/1860/1*87KlGgfbuWP38nAaQaj3xw.png" width="930" height="523"/><figcaption>CPU profiling after optimizations</figcaption></figure><p>As you can notice, we have to zoom to the profile if we want to see the call stack, because after optimizations the API was able to take a lot more traffic. Now every function in the call stack looks like a microtask.</p><figure><img alt="CPU profiling after optimization" src="https://miro.medium.com/max/3688/1*EO-pr4RolgcAOj_Uk1rpDA.png" width="1844" height="576"/><figcaption>Zoom in the CPU profiling</figcaption></figure><p>And now our application is able to serve more than 200,000 requests in 20 seconds; <strong>we increased the performance by a factor of 100k</strong>!</p><figure><img src="https://miro.medium.com/max/1690/1*kfOK60PtmWx6iP681-qRcg.png" width="845" height="362"/><figcaption>&lt;img class=&#34;s t u hy ai&#34; src=&#34;https://miro.medium.com/max/1690/1*kfOK60PtmWx6iP681-qRcg.png&#34; width=&#34;845&#34; height=&#34;362&#34; role=&#34;presentation&#34;/&gt;</figcaption></figure><h1>More than just CPU profiling</h1><p>With the inspector module, you can do much more than just CPU profiling, here is a non-exhaustive list:</p><ul><li>memory dump &amp; memory sampling</li><li>code coverage</li><li>use the debugger in real-time</li></ul><h1>Warnings</h1><p>Every tool, even the most powerful, comes with its own disadvantages. If you enable the profiler and/or the debugger on your production you have to keep an eye on two things:</p><p><strong>1) performance overhead</strong></p><p>A profiler needs to use CPU to work and it collects data into memory. The longer you let it run and the more CPU / memory it will need. This is why you should begin with very short CPU profiling, no more than a few seconds between the start and stop command. And never forget to monitor the impact of the profiler on your own infrastructure. If everything is fine you can increase the time and the frequency of CPU profiling.</p><p>One more very important thing: <strong>never forget to always stop a started CPU profiling</strong>. You can add a timer to automatically call the stop function after a while.</p><p><strong>2) security</strong></p><p>Using the inspector in Node.js it’s like opening the door of the core of your application. You should be very careful about who can use features like CPU profiling and/or the debugger. Never make the inspector “public” as being able to launch a feature from an unsafe route (not protected with an authentification mechanism). Even the collected data can be seen as critical, never send it to a system you do not trust.</p><h1>Conclusion</h1><p>CPU profiling is really a must-have tool for every developer. And now, with some precautions, we can run it on production thanks to the amazing work done by the V8 and Node.js team.</p><p>The inspector module offers a lot more features than you can use to debug your application.</p><p>I will write another article about using CPU profiling and the inspector on production on a high traffic project.</p>